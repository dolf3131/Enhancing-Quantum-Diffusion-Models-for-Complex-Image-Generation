\documentclass[12pt]{article}
\usepackage{fullpage,enumitem,amsmath,amssymb,graphicx}
%\usepackage[hangul]{kotex}
\usepackage[style=plain, backend=biber]{biblatex}

\title{
    \textbf{QAMP 2025} \\        
    \vspace{0.5em}                            
    \small \textit{Enhancing Quantum Diffusion Models for Complex Image Generation}            
}



\addbibresource{bibliography.bib}

\author{
  Jeongbin Jo \\ 
  \texttt{jeongbin033@yonsei.ac.kr}
}

\begin{document}
  \maketitle
  \tableofcontents
  \begin{center}

  %\vspace{-0.3in}
  %\begin{tabular}{rl}
  %Collaborators: & 
  %\end{tabular}
  \end{center}

  

  \noindent
  \rule{\linewidth}{0.4pt}
  
  \section{Motivation}
  \subsection{Whatâ€™s the potential benefit of replacing neural network with PQCs?}
    
    \subsubsection*{Parameter Efficiency (Model Compression)}
    The authors state in their conclusion that "quantum diffusion models require fewer parameters with respect to their classical counterpart". 
    For example, their 'conditioned latent' model, which generated all 10 MNIST digits, used only 1110 parameters. 
    This is a massive reduction compared to the millions of parameters typical in classical U-Net architectures used for diffusion. 

    \subsubsection*{Expressivity and Scalability}
    The paper suggests that for a "full quantum case," it is "possible to generate distributions whose features scale exponentially with the number of qubits". 
    This implies PQCs have a fundamentally greater expressive power.


    \subsubsection*{Future Potential}
    The long-term benefit is the potential to "approximate probability distributions that are not classically tractable", including "quantum datasets" themselves.


  \subsection{How does the proposed QDM compare to just classical DM?}
    \subsubsection*{Hybrid Architecture}
    The paper's QDM is a hybrid model. 
    The forward process (adding noise) is performed classically. 
    The backward process (denoising) is performed by a PQC.


    \subsubsection*{PQC as a Denoising Operator}
    Instead of having the PQC predict the noise $\epsilon_{\theta}$ (like a classical U-Net), this model trains the PQC to be a direct denoising operator $P(\theta,t)$ such that **$P(\theta,t)|x_{t}\rangle=|x_{t-1}\rangle$**. 
    This avoids the "impractical" cycle of decoding/encoding quantum states at every timestep.


    \subsubsection*{Use of Complex Noise}
    Because PQC operations can make state coefficients complex, the authors found that using complex Gaussian noise ($\epsilon = \epsilon_r + i\epsilon_i$) during the classical forward process led to a "significant improvement in performance". 
    This is a notable departure from classical models.


    \subsubsection*{Comparable Performance (in Latent Space)}
    The paper's 'Latent QDM' (which uses a classical autoencoder first) achieved a competitive FID of 38.2 and was able to generate "samples of similar quality to those generated by classical algorithms".



\section{Implementation}
  \subsection{Architecture}


\printbibliography

\end{document}